{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7391487-7c70-42cb-8dbf-a8e11c991009",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7fa925b74d10>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7fa921394cd0, raw_cell=\"import os\n",
      "import time\n",
      "import psutil\n",
      "import torch\n",
      "i..\" store_history=True silent=False shell_futures=True cell_id=c7391487-7c70-42cb-8dbf-a8e11c991009>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main execution...\n",
      "Loading datasets...\n",
      "Preprocessing text data...\n",
      "Adding synthetic data...\n",
      "Original Text: breaking: 3 liber celebr arrest conspiraci assassin presid trump | Original Label: 0\n",
      "Synthetic Text: breaking: 3 liber celebr arrest conspiraci assassin presid trump\n",
      "\n",
      "\"It is a shame that a few of the men involved in this attack were not prosecuted for their role in the attack,\" he said.\n",
      " (Reporting by Robert Birnbaum | Label: 0\n",
      "Original Text: michel obama receiv life-shatt news doctor | Original Label: 0\n",
      "Synthetic Text: michel obama receiv life-shatt news doctor\n",
      "\n",
      "New Delhi: A woman was killed after her body was found in a road in Jammu and Kashmir city on Saturday, police said.\n",
      "\n",
      "\n",
      "\n",
      "The body of Atef | Label: 0\n",
      "Original Text: breaking: barcelona terrorist cousin u name barack | Original Label: 0\n",
      "Synthetic Text: breaking: barcelona terrorist cousin u name barack\n",
      "\n",
      "U.S. senator and New Jersey Gov. Chris Christie, the Republican presidential nominee, speaks at a news conference in New York on July 17. REUTERS/Brendan McDermid\n",
      " | Label: 0\n",
      "Original Text: rice told investig unmask trump aid | Original Label: 0\n",
      "Synthetic Text: rice told investig unmask trump aid for Trump's wife, Ivana Trump, who is now under investigation by the FBI for possible Russian interference in the election.\n",
      "\n",
      "\"In an effort to prevent the Russian government from interfering in our election, we | Label: 0\n",
      "Original Text: i’ll make sure jailed- donald trump tell ghana’ prez mahama ⋆ ghana home, ghana news, politics, info, news ghana, ghana | Original Label: 0\n",
      "Synthetic Text: i’ll make sure jailed- donald trump tell ghana’ prez mahama ⋆ ghana home, ghana news, politics, info, news ghana, ghana (hana)‭‮� | Label: 0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import psutil\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    precision_recall_fscore_support,\n",
    "    matthews_corrcoef,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    auc,\n",
    ")\n",
    "from datasets import Dataset as HFDataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    TrainerCallback,\n",
    "    DataCollatorWithPadding,\n",
    "    GPT2Tokenizer,\n",
    "    GPT2LMHeadModel,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import re\n",
    "import unicodedata\n",
    "import gc\n",
    "\n",
    "# Ensure NLTK data is downloaded\n",
    "nltk.download('wordnet')\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Configuration Class\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.dataset_path = \"/notebooks/FakeNewsNet/dataset/\"\n",
    "        self.fake_news_file = \"politifact_fake.csv\"\n",
    "        self.real_news_file = \"politifact_real.csv\"\n",
    "        self.text_column = \"title\"\n",
    "        self.label_column = \"label\"\n",
    "        self.hyperparameter_optimization_enabled = False\n",
    "        self.wandb_project_name = \"GossipCop\"\n",
    "        self.model_name = \"FacebookAI/roberta-base\"\n",
    "        self.num_trials = 10\n",
    "        self.learning_rate = 2e-5\n",
    "        self.num_train_epochs = 6\n",
    "        self.per_device_train_batch_size = 8\n",
    "        self.tokenizer_max_length = 512\n",
    "        self.min_word_count = 6\n",
    "        self.balance_ratio = 0.8\n",
    "        self.diagnostics_enabled = True\n",
    "        self.num_fake_samples = 10\n",
    "        self.num_real_samples = 10\n",
    "        self.freeze_bert_layers = 0\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# Set device based on availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Preprocessing functions\n",
    "def preprocess_text(text, config):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    words = text.split()\n",
    "\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "    words = [stemmer.stem(word.lower()) for word in words]\n",
    "    words = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
    "\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Initialize GPT-2\n",
    "def initialize_gpt2():\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "    model = GPT2LMHeadModel.from_pretrained(\"gpt2\").to(device)\n",
    "    return tokenizer, model\n",
    "\n",
    "gpt2_tokenizer, gpt2_model = initialize_gpt2()\n",
    "\n",
    "def generate_synthetic_text(text, num_samples=1, max_length=50):\n",
    "    synthetic_texts = []\n",
    "    input_ids = gpt2_tokenizer.encode(text, return_tensors='pt').to(device)\n",
    "    \n",
    "    for _ in range(num_samples):\n",
    "        output = gpt2_model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            no_repeat_ngram_size=2,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            temperature=0.7,\n",
    "            do_sample=True,\n",
    "            pad_token_id=gpt2_tokenizer.eos_token_id\n",
    "        )\n",
    "        generated_text = gpt2_tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        synthetic_texts.append(generated_text)\n",
    "    \n",
    "    return synthetic_texts\n",
    "\n",
    "def add_synthetic_data(data, text_column, label_column, config):\n",
    "    synthetic_data = []\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        text = row[text_column]\n",
    "        label = row[label_column]\n",
    "\n",
    "        if not text.strip():\n",
    "            continue\n",
    "\n",
    "        synthetic_texts = generate_synthetic_text(text)\n",
    "\n",
    "        for synthetic_text in synthetic_texts:\n",
    "            if synthetic_text and synthetic_text.strip():\n",
    "                synthetic_data.append({text_column: synthetic_text, label_column: label})\n",
    "                if config.diagnostics_enabled:\n",
    "                    print(f\"Original Text: {text} | Original Label: {label}\")\n",
    "                    print(f\"Synthetic Text: {synthetic_text} | Label: {label}\")\n",
    "\n",
    "    synthetic_df = pd.DataFrame(synthetic_data)\n",
    "    data = pd.concat([data, synthetic_df], ignore_index=True)\n",
    "    return data\n",
    "\n",
    "def load_and_preprocess_data(config):\n",
    "    print(\"Loading datasets...\")\n",
    "    fake_news_path = os.path.join(config.dataset_path, config.fake_news_file)\n",
    "    real_news_path = os.path.join(config.dataset_path, config.real_news_file)\n",
    "    \n",
    "    fake_news = pd.read_csv(fake_news_path)\n",
    "    real_news = pd.read_csv(real_news_path)\n",
    "\n",
    "    if config.num_fake_samples != -1:\n",
    "        fake_news = fake_news.sample(n=config.num_fake_samples)\n",
    "    if config.num_real_samples != -1:\n",
    "        real_news = real_news.sample(n=config.num_real_samples)\n",
    "\n",
    "    fake_news[config.label_column] = 0  # 0 for fake\n",
    "    real_news[config.label_column] = 1  # 1 for real\n",
    "    data = pd.concat([fake_news, real_news], ignore_index=True)\n",
    "\n",
    "    data = data[[config.label_column, config.text_column]]\n",
    "\n",
    "    data.dropna(subset=[config.text_column], inplace=True)\n",
    "\n",
    "    print(\"Preprocessing text data...\")\n",
    "    data[config.text_column] = data[config.text_column].apply(\n",
    "        lambda x: preprocess_text(x, config)\n",
    "    )\n",
    "\n",
    "    data = data[data[config.text_column].str.strip() != \"\"]\n",
    "\n",
    "    # Generate and add synthetic data\n",
    "    print(\"Adding synthetic data...\")\n",
    "    data = add_synthetic_data(data, config.text_column, config.label_column, config)\n",
    "\n",
    "    print(\"Data loading and preprocessing complete.\")\n",
    "    return data\n",
    "\n",
    "def tokenize_data(tokenizer, data, text_column, label_column, max_length, diagnostics_enabled):\n",
    "    print(\"Tokenizing data...\")\n",
    "\n",
    "    # Add an index column to the data to keep track of original rows\n",
    "    data = data.reset_index()\n",
    "    data.rename(columns={'index': 'original_index'}, inplace=True)\n",
    "\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[text_column],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=max_length\n",
    "        )\n",
    "\n",
    "    # Convert the DataFrame to a Hugging Face Dataset\n",
    "    dataset = HFDataset.from_pandas(data)\n",
    "    \n",
    "    # Tokenize the dataset\n",
    "    dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    # Only split if we have enough samples\n",
    "    if len(dataset) > 1:\n",
    "        train_test_split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "        train_dataset = train_test_split['train']\n",
    "        test_dataset = train_test_split['test']\n",
    "    else:\n",
    "        train_dataset = dataset\n",
    "        test_dataset = None\n",
    "\n",
    "    if diagnostics_enabled:\n",
    "        num_samples_to_check = min(10, len(train_dataset))\n",
    "        print(f\"\\n--- Sample Tokenized Training Data ({num_samples_to_check} samples) ---\")\n",
    "        for i in range(num_samples_to_check):\n",
    "            original_index = train_dataset[i]['original_index']\n",
    "            assert 'input_ids' in train_dataset[i], f\"input_ids not found in sample {i}\"\n",
    "            assert 'attention_mask' in train_dataset[i], f\"attention_mask not found in sample {i}\"\n",
    "            assert label_column in train_dataset[i], f\"label not found in sample {i}\"\n",
    "\n",
    "            print(f\"Sample {i+1}:\")\n",
    "            print(\"Title:\", data.iloc[original_index][text_column])\n",
    "            print(\"Tokenized Input IDs:\", train_dataset[i]['input_ids'])\n",
    "            print(\"Tokenized Attention Mask:\", train_dataset[i]['attention_mask'])\n",
    "            print(\"Original Label:\", data.iloc[original_index][label_column])\n",
    "            print(\"Label:\", train_dataset[i][label_column])\n",
    "            print(\"--------------------\")\n",
    "\n",
    "    if diagnostics_enabled and test_dataset is not None:\n",
    "        num_samples_to_check = min(10, len(test_dataset))\n",
    "        print(f\"\\n--- Sample Tokenized Testing Data ({num_samples_to_check} samples) ---\")\n",
    "        for i in range(num_samples_to_check):\n",
    "            original_index = test_dataset[i]['original_index']\n",
    "            assert 'input_ids' in test_dataset[i], f\"input_ids not found in sample {i}\"\n",
    "            assert 'attention_mask' in test_dataset[i], f\"attention_mask not found in sample {i}\"\n",
    "            assert label_column in test_dataset[i], f\"label not found in sample {i}\"\n",
    "\n",
    "            print(f\"Sample {i+1}:\")\n",
    "            print(\"Title:\", data.iloc[original_index][text_column])\n",
    "            print(\"Tokenized Input IDs:\", test_dataset[i]['input_ids'])\n",
    "            print(\"Tokenized Attention Mask:\", test_dataset[i]['attention_mask'])\n",
    "            print(\"Original Label:\", data.iloc[original_index][label_column])\n",
    "            print(\"Label:\", test_dataset[i][label_column])\n",
    "            print(\"--------------------\")\n",
    "\n",
    "    print(\"Tokenization complete.\")\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    if isinstance(eval_pred, tuple):\n",
    "        logits, labels = eval_pred\n",
    "    else:\n",
    "        logits = eval_pred.predictions\n",
    "        labels = eval_pred.label_ids\n",
    "        \n",
    "    preds = logits.argmax(axis=-1)\n",
    "\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"binary\", zero_division=0\n",
    "    )\n",
    "    mcc = matthews_corrcoef(labels, preds)\n",
    "    try:\n",
    "        auc_score = roc_auc_score(labels, logits[:, 1])\n",
    "    except ValueError:\n",
    "        auc_score = float('nan')\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"auc\": auc_score,\n",
    "        \"mcc\": mcc,\n",
    "    }\n",
    "\n",
    "class FinalMetricsCallback(TrainerCallback):\n",
    "    def __init__(self, trainer, eval_dataset):\n",
    "        self.trainer = trainer\n",
    "        self.eval_dataset = eval_dataset\n",
    "\n",
    "    def on_evaluate(self, args, state, control, **kwargs):\n",
    "        predictions = self.trainer.predict(self.eval_dataset)\n",
    "        metrics = compute_metrics((predictions.predictions, self.eval_dataset[config.label_column]))\n",
    "        print(\"\\nFinal Metrics after evaluation:\")\n",
    "        for key, value in metrics.items():\n",
    "            print(f\"{key.capitalize()}: {value:.4f}\")\n",
    "\n",
    "def plot_metrics(trainer_state, predictions, labels):\n",
    "    train_loss = [x['loss'] for x in trainer_state.log_history if 'loss' in x]\n",
    "    eval_loss = [x['eval_loss'] for x in trainer_state.log_history if 'eval_loss' in x]\n",
    "    eval_accuracy = [x['eval_accuracy'] for x in trainer_state.log_history if 'eval_accuracy' in x]\n",
    "    train_accuracy = [x['accuracy'] for x in trainer_state.log_history if 'accuracy' in x]\n",
    "\n",
    "    # Print debug information\n",
    "    print(f\"Train Loss: {train_loss}\")\n",
    "    print(f\"Eval Loss: {eval_loss}\")\n",
    "    print(f\"Train Accuracy: {train_accuracy}\")\n",
    "    print(f\"Eval Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    # Truncate to match lengths\n",
    "    min_length = min(len(train_loss), len(eval_loss), len(eval_accuracy), len(train_accuracy))\n",
    "    \n",
    "    if min_length == 0:\n",
    "        print(\"No sufficient data for plotting.\")\n",
    "        return  # Exit early if no data is available\n",
    "    \n",
    "    train_loss = train_loss[:min_length]\n",
    "    eval_loss = eval_loss[:min_length]\n",
    "    eval_accuracy = eval_accuracy[:min_length]\n",
    "    train_accuracy = train_accuracy[:min_length]\n",
    "\n",
    "    epochs = range(1, min_length + 1)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(labels, predictions[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    conf_matrix = confusion_matrix(labels, predictions.argmax(axis=-1))\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    axs[0, 0].plot(epochs, train_loss, 'bo-', label='Training loss')\n",
    "    axs[0, 0].plot(epochs, eval_loss, 'ro-', label='Validation loss')\n",
    "    axs[0, 0].set_title('Training and Validation Loss')\n",
    "    axs[0, 0].set_xlabel('Epochs')\n",
    "    axs[0, 0].set_ylabel('Loss')\n",
    "    axs[0, 0].set_xticks(epochs)\n",
    "    axs[0, 0].legend()\n",
    "    axs[0, 0].set_ylim(bottom=min(min(train_loss), min(eval_loss)) - 0.01, top=max(max(train_loss), max(eval_loss)) + 0.01)\n",
    "\n",
    "    axs[0, 1].plot(epochs, train_accuracy, 'bo-', label='Training accuracy')\n",
    "    axs[0, 1].plot(epochs, eval_accuracy, 'ro-', label='Validation accuracy')\n",
    "    axs[0, 1].set_title('Training and Validation Accuracy')\n",
    "    axs[0, 1].set_xlabel('Epochs')\n",
    "    axs[0, 1].set_ylabel('Accuracy')\n",
    "    axs[0, 1].set_xticks(epochs)\n",
    "    axs[0, 1].legend()\n",
    "    axs[0, 1].set_ylim(bottom=min(min(train_accuracy), min(eval_accuracy)) - 0.01, top=max(max(train_accuracy), max(eval_accuracy)) + 0.01)\n",
    "\n",
    "    axs[1, 0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    axs[1, 0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    axs[1, 0].set_xlim([0.0, 1.0])\n",
    "    axs[1, 0].set_ylim([0.0, 1.05])\n",
    "    axs[1, 0].set_xlabel('False Positive Rate')\n",
    "    axs[1, 0].set_ylabel('True Positive Rate')\n",
    "    axs[1, 0].set_title('Receiver Operating Characteristic (ROC)')\n",
    "    axs[1, 0].legend(loc=\"lower right\")\n",
    "\n",
    "    sns.heatmap(\n",
    "        conf_matrix,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=[\"Fake\", \"Real\"],\n",
    "        yticklabels=[\"Fake\", \"Real\"],\n",
    "        cbar=False,\n",
    "        ax=axs[1, 1]\n",
    "    )\n",
    "    axs[1, 1].set_xlabel(\"Predicted\")\n",
    "    axs[1, 1].set_ylabel(\"True\")\n",
    "    axs[1, 1].set_title(\"Confusion Matrix - Final Model\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def freeze_layers(model, num_layers_to_freeze):\n",
    "    \"\"\"Freezes the first `num_layers_to_freeze` layers of the model.\"\"\"\n",
    "    if hasattr(model, 'bert'):\n",
    "        encoder_layers = model.bert.encoder.layer\n",
    "    elif hasattr(model, 'roberta'):\n",
    "        encoder_layers = model.roberta.encoder.layer\n",
    "    elif hasattr(model, 'distilbert'):\n",
    "        encoder_layers = model.distilbert.transformer.layer\n",
    "    elif hasattr(model, 'albert'):\n",
    "        encoder_layers = model.albert.encoder.albert_layer_groups\n",
    "    elif hasattr(model, 'electra'):\n",
    "        encoder_layers = model.electra.encoder.layer\n",
    "    else:\n",
    "        raise ValueError(\"Model type not supported for freezing layers.\")\n",
    "    \n",
    "    for i in range(num_layers_to_freeze):\n",
    "        if hasattr(encoder_layers, '__len__') and i < len(encoder_layers):\n",
    "            for param in encoder_layers[i].parameters():\n",
    "                param.requires_grad = False\n",
    "        else:\n",
    "            raise ValueError(f\"Model does not have {num_layers_to_freeze} layers to freeze.\")\n",
    "\n",
    "def main():\n",
    "    print(\"Starting main execution...\")\n",
    "    data = load_and_preprocess_data(config)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    train_dataset, test_dataset = tokenize_data(tokenizer, data, config.text_column, config.label_column, config.tokenizer_max_length, config.diagnostics_enabled)\n",
    "\n",
    "    if config.wandb_project_name:\n",
    "        import wandb\n",
    "        wandb.init(project=config.wandb_project_name, config={\n",
    "            \"learning_rate\": config.learning_rate,\n",
    "            \"epochs\": config.num_train_epochs,\n",
    "            \"batch_size\": config.per_device_train_batch_size,\n",
    "            \"model_name\": config.model_name\n",
    "        })\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        num_train_epochs=config.num_train_epochs,\n",
    "        per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "        per_device_eval_batch_size=config.per_device_train_batch_size,\n",
    "        learning_rate=config.learning_rate,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        logging_dir=\"./logs\",\n",
    "        logging_steps=10,\n",
    "        load_best_model_at_end=True,\n",
    "        weight_decay=0.1,\n",
    "        report_to=\"wandb\" if config.wandb_project_name else []\n",
    "    )\n",
    "\n",
    "    print(\"Loading the final model for training...\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(config.model_name, num_labels=2).to(device)\n",
    "\n",
    "    if config.freeze_bert_layers > 0:\n",
    "        print(f\"Freezing the first {config.freeze_bert_layers} layers of the model.\")\n",
    "        freeze_layers(model, config.freeze_bert_layers)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer)\n",
    "    )\n",
    "\n",
    "    trainer.add_callback(FinalMetricsCallback(trainer, test_dataset))\n",
    "\n",
    "    start_time = time.time()\n",
    "    print(\"Training the final model...\")\n",
    "    trainer.train()\n",
    "    end_time = time.time()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_usage = process.memory_info().rss / (1024 ** 3)\n",
    "\n",
    "    print(f\"Training time: {(end_time - start_time) / 60:.2f} minutes\")\n",
    "    print(f\"Memory usage: {memory_usage:.2f} GB\")\n",
    "\n",
    "    for epoch in range(config.num_train_epochs):\n",
    "        train_output = trainer.predict(train_dataset)\n",
    "        train_metrics = compute_metrics((train_output.predictions, train_output.label_ids))\n",
    "        eval_output = trainer.evaluate()\n",
    "        print(f\"Epoch {epoch + 1} - Training Accuracy: {train_metrics['accuracy']:.4f}, Validation Accuracy: {eval_output['eval_accuracy']:.4f}\")\n",
    "\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    preds = predictions.predictions.argmax(-1)\n",
    "    labels = test_dataset[config.label_column]\n",
    "\n",
    "    metrics = compute_metrics((predictions.predictions, labels))\n",
    "\n",
    "    print(\"\\nFinal Evaluation Metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key.capitalize()}: {value:.4f}\")\n",
    "\n",
    "    report = classification_report(labels, preds, target_names=[\"Fake\", \"Real\"])\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "    plot_metrics(trainer.state, predictions.predictions, labels)\n",
    "\n",
    "    if config.wandb_project_name:\n",
    "        wandb.finish()\n",
    "\n",
    "    del trainer, model, predictions\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"Main execution complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044b6ba0-52f9-4ca3-9677-5098f7cd3215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
